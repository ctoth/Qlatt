This paper presents a complete synthesis-by-rule architecture that converts discrete phoneme symbols into continuous synthesizer control signals using a two-stage strategy combining linguistic preprocessing with segmental formant modeling and suprasegmental F0 control. The key contributions include a critically-damped differential equation model for smooth formant transitions, dynamic timing control based on frequency region tolerance bands rather than fixed durations, and a physiological F0 model based on subglottal pressure with three-component contours (archetypal declination, stress perturbation, and consonant perturbation). This work is fundamental for TTS systems because it establishes the principle that formant transitions must be continuous and smooth, demonstrates that timing should be driven by target attainment rather than absolute segment lengths, and provides a reusable framework for separating linguistic rules from acoustic parameter generation.
