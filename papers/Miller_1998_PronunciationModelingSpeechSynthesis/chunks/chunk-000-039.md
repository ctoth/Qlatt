# Pages 000-039 Notes

## Document Information
- **Title:** Pronunciation Modeling in Speech Synthesis
- **Author:** Corey Andrew Miller
- **Type:** PhD Dissertation in Linguistics
- **Institution:** University of Pennsylvania
- **Year:** 1998
- **Supervisor:** Mark Liberman
- **Committee:** William Labov, Eugene Buckley, Mark Randolph (external, Motorola)

## Chapters/Sections Covered
- Front matter (title, copyright, dedication, acknowledgments, abstract)
- Table of Contents (pages viii-x)
- List of Tables (pages xi-xiii)
- List of Illustrations (pages xiv-xv)
- **Chapter 1. Introduction** (pages 1-48)
  - 1.1. What is speech synthesis pronunciation modeling?
  - 1.2. Computational phonology and speech technology
    - 1.2.1. Linguistic aspects of speech synthesis (partial)
    - 1.2.2. Review of prior work in postlexical modeling (partial)
    - 1.2.3. Review of neural networks in phonology (beginning)

## Key Findings

### Definition of Pronunciation Modeling
- Pronunciation modeling = architectures and principles for generating high-quality human-like pronunciations
- In speech recognition: handles pronunciation variation across speakers
- In speech synthesis: requires modeling pronunciation variation of an INDIVIDUAL whose speech is being modeled (p. 1)

### TTS Pipeline Architecture (Motorola Synthesizer)
The Motorola synthesizer ("MotorMouth") uses neural networks throughout:
1. **Text Analyzer** - text preprocessing (numbers to words, punctuation handling)
   - Tokenizes text into word-sized units
   - Looks up words in lexical database
   - POS disambiguation module for homographs
2. **Letter-to-Sound Conversion** - handles unknown words not in dictionary
3. **Postlexical Module** - transforms lexical pronunciations to contextual surface forms
   - Handles flapping, t/d deletion, insertions, substitutions
4. **Duration Module** - assigns phone durations using neural network
5. **Phonetic Implementation Module** (Acoustic Module) - transforms phonological representation to spectral parameters

### Key Distinction: Lexical vs. Postlexical
- **Lexical pronunciations**: dictionary/canonical forms (phonemic)
- **Postlexical pronunciations**: actual surface forms in connected speech (phonetic)
- The postlexical module learns correspondences between these two levels

### Synthesis Approaches
- **Concatenative synthesis**: strings together acoustic subword units (phones, diphones, demidiphones)
- **Synthesis by rule**: generates acoustic parameters from linguistic analysis (e.g., Allen et al. 1987)
- The phoneme is maintained as a useful intermediate representation

### Training New Voices
For each new voice, retrain:
1. Postlexical module neural network
2. Duration module
3. Acoustic module
This accounts for three sources of idiosyncratic behavior:
- Dictionary transcriptions
- Speech database labeling
- Speaker's personal habits

### Speech Recognition Error Rates (Table 1-1, p. 18)
| Task | Human word error rate | Machine word error rate |
|------|----------------------|------------------------|
| Wall Street Journal | 1% | 12% |
| Switchboard (spontaneous) | 4% | 66% |

This shows postlexical variation is critical - spontaneous speech has highest error rates.

### Factors Affecting Pronunciation (Table 1-2, p. 24)
From Fulop and Keating (1996) study of Switchboard corpus:
| Factor | Majority class | Phones affected |
|--------|---------------|-----------------|
| Preceding/following phoneme | vowels | ae, ^, E, e, I, o, b, f |
| Syllable structure position | resonants | l, n, r |
| Position within word/syllable | plosives | d, k, t |
| No major context effects | stridents, labials | m, s, v, w, z |

### Central Vowel Distribution in TIMIT (p. 22)
From Byrd (1994):
- 55% [i] (barred-i)
- 18% [^] (caret/wedge)
- 27% [schwa]
- NYC and West prefer [i], North Midland prefers [schwa]

### Speaking Rate Gender Differences
From Byrd (1994) TIMIT study:
- Men: 4.69 syllables/second (p < .0001)
- Women: 4.42 syllables/second
- Women exhibited more conservative postlexical behavior:
  - Released sentence-final stops more often
  - Produced significantly fewer flaps

## Equations Found
None in this chunk - primarily descriptive/architectural content.

## Parameters/Rules Found
| Rule/Parameter | Description | Value/Pattern | Page |
|----------------|-------------|---------------|------|
| Transcriber reliability threshold (high) | Agreement level for reliable transcription | >= 90% | 23 |
| Transcriber reliability threshold (low) | Agreement level for less reliable | >= 70% | 23 |
| Male speaking rate | Average syllables per second | 4.69 syl/s | 21 |
| Female speaking rate | Average syllables per second | 4.42 syl/s | 21 |

## Algorithms/Procedures

### TTS Processing Pipeline
1. Text input received
2. Text Analyzer performs preprocessing:
   - Translate numbers/symbols to orthographic words
   - Handle e-mail headers, HTML codes, graphical objects
3. Tokenize into word-sized units
4. Look up each word in lexical database
5. Disambiguation module assigns POS and semantic info for homographs
6. If word not in dictionary: Letter-to-Sound conversion generates pronunciation
7. Construct lexical phonological representation (hierarchical: phones, syllables, words)
8. Postlexical Module transforms to surface form
9. Duration Module assigns phone durations
10. Phonetic Implementation Module generates spectral parameters
11. Synthesize speech waveform

### Learning Biases for Postlexical Modeling (Gildea & Jurafsky 1996)
Three types of biases introduced:
1. **Faithfulness**: input-output correspondence via dynamic programming alignment
2. **Community**: similarities between segments expressed by distinctive features
3. **Context**: knowledge of preceding and following phonological environments

## Figures of Interest
- **Figure 1-1 (page 8):** Motorola speech synthesizer architecture diagram - shows full TTS pipeline from Text through modules to Speech output
- **Figure 1-2 (page 12):** Motorola synthesizer training scheme - shows how Labeled Speech Database feeds Postlexical Phonological Representation which trains three modules (Postlexical, Duration, Acoustic)
- **Figure 1-3 (page 25):** Percentage of tokens transcribed using canonical pronunciations - bar chart showing different phones have vastly different faithfulness to dictionary (schwa ~16%, h ~30%, stops 40-60%, stridents ~95-100%)

## Tables of Interest
- **Table 1-1 (page 18):** Speech recognition performance comparing human vs machine on read (WSJ) and spontaneous (Switchboard) speech
- **Table 1-2 (page 24):** Factors contributing to varying realization of phones - maps phonetic context factors to affected phone classes

## Quotes Worth Preserving

> "in the future, in text-to-speech systems, some segments and even syllables will disappear entirely and certain functors will be greatly attenuated." - Divay and Vitale (1997), p. 1

> "One problem with these particular approaches is that since the decision tree for each segment is learned separately, the technique has difficulty forming generalizations about the behavior of similar segments. In addition, no generalizations are made about segments in similar contexts, or about long-distance dependencies." - Gildea and Jurafsky (1996) criticizing decision trees, p. 19

> "no phonemic transcription is provided, automating an investigation into many phonological processes is difficult or impossible" - Byrd (1994) on TIMIT limitations, p. 22

## Implementation Notes

### Key Architecture Insight
The Motorola synthesizer's use of neural networks throughout allows:
- Learning individual speaker characteristics
- Potential reversibility for speech recognition
- Adaptation to new voices with retraining only (no rule rewriting)

### Critical for TTS Implementation
1. **Lexical database lookup before LTS**: Only use letter-to-sound for unknown words
2. **POS tagging for homographs**: Essential for correct pronunciation (e.g., "read" past vs present)
3. **Postlexical rules are speaker-dependent**: What varies between speakers is which rules apply and how often

### Phone Classes by Context Sensitivity
Implementation should treat these differently:
- **Context-sensitive**: vowels (ae, ^, E, e, I, o), voiced stops (b), fricatives (f)
- **Position-sensitive**: resonants (l, n, r), plosives (d, k, t)
- **Context-insensitive**: stridents (s, z), labials (m, v, w)

### Function Words Need Special Handling
Low-reliability transcription words are predominantly function words:
- High reliability (>= 90%): bear, chips, farmers, goal, like, therefore
- Low reliability (>= 70%): but, customer, have, I, to, was, wasn't, what's

## Cross-References

### Key Papers Referenced
- **Allen et al. (1987)** - Synthesis by rule; MITalk system
- **Sejnowski and Rosenberg (1987)** - NETtalk; learning orthography-phonetics conversion with neural networks
- **Rumelhart and McClelland (1986)** - Neural networks for past tense learning
- **Gildea and Jurafsky (1996)** - Finite state transducers for lexical-postlexical conversion
- **Riley and Ljolje (1996)** - Pronunciation networks with decision trees; 3% WER improvement
- **Withgott and Chen (1993)** - Decision trees for TIMIT postlexical variation
- **Keating et al. (1994)** - TIMIT variation study
- **Byrd (1994)** - Sex/dialect and reduction in TIMIT
- **Fulop and Keating (1996)** - Switchboard corpus pronunciation variation
- **Seneff and Zue (1988)** - TIMIT transcription principles
- **Church (1988)** - POS tagging
- **Yarowsky (1997)** - Semantic disambiguation
- **Fitt (1997)** - Regional accents in speech synthesis
  - Pre-lexicon transformations
  - Post-lexicon transformations (allophones like flapping)
  - Connected speech rules

### Dissertation Internal Cross-References
- Section 3.1 - Lexical database
- Section 3.2 - Labeled speech corpus
- Section 5.1 - Entropy as variability measure
- Section 6.4 - Reduced vowels
- Section 6.5 - Function word reduction
