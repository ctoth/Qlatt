# Abstract

## Original Text (Verbatim)

The MITalk system described in this book is the result of a long effort, stretching from the early 1960s to the present. In this preface, a view is given of the work's historical evolution. Within this description, acknowledgments are made of the project's many contributions. In recognizing these contributions, it is best to organize them into four groups. First, there was the development of the MITalk system, and the many different contributions made to its structure and content. Second, there was the 1979 summer course which resulted in a one-page synthesis of the work to that date, and also provided the occasion to write a set of course notes. Next, there have been continuing efforts (since 1980) which include the writing of the system's software, and the effort to organize this book which involved substantial new writing and rule formulations, and explicit examples closely keyed to the current working system. Finally, there is the sponsorship of the program's many facets over the years.

In the years immediately succeeding and within the CIA initiative information Processing Group at MIT's Research Laboratory of Electronics. This group, led by Dr. Klatt and S. J. Mason, focused on the development of some story aids to the blind. Many approaches were taken, but it was recognized that the development of a reading machine for the blind that could scan printed text and produce spoken output was a major goal. Research efforts in both character recognition and speech synthesis were initiated. By 1966, a functional reading machine was demonstrated. Once the character was recognized (using a contour scanning algorithm), text-to-speech conversion was accomplished in two phases. First, a rough decomposition analysis of all words was performed by using techniques developed by F. J. Lee (at the 1005 doctoral thesis). A rough lexicon sufficient for these demonstrations was developed. It was anticipated that any exceptional words encountered in the actual synthesis would be pronounced correctly using pitched speech. As a result, these words were heard as a sequence of individually pronounced letters. The dictionary provided names of the phonetic sequences for each morph, and synthesis was performed using the algorithms developed and published by Hermes, Mattingly, and Shearme. An analog synthesizer was used to produce the output speech waveform based on the work of these three researchers, the resonances for the speech being provided by digitally controlled operational amplifiers. The demonstration of this system was impressive, although the vocabulary was restricted, and the output speech quality required extensive learning. At that time, the computer implementation used for research consisted of a Digital Equipment Corporation PDP-1 used for character recognition and morph analysis, which was coupled to MIT Lincoln Laboratory's TX-0 computer (the only one of its kind). The on-line synthesis algorithms. T. S. Burnell III and E. R. Jensen were responsible for building much of this computational environment. The project put effort and coordination, since all coding was performed in assembly language.

Following late 1968, the character recognition and speech synthesis of efforts continued independently of one another with the work of B. Blesser, M. Eden, and D. Klatt, focused on the character recognition efforts. J. Allen joined the faculty in September, 1968. Goals for a fundamental and comprehensive program aimed at the generation of high-quality speech utilizing restricted English text as input were formulated. In addition, strong coupling continues with the Speech Communications and Linguistics groups within the Research Laboratory of Electronics, led by K. N. Stevens and M. Halle, respectively.

With the desire to convert unrestricted English text to speech, a new scheme was developed for the pronunciation of all possible English words. This required elaborate extensions to the morph decomposition process, as well as the construction of a comprehensive pseudo-lexicon to serve the entire language of English. Nevertheless, the initial speech was rejected as inadequate, and plans for the development of a more comprehensive rules (as well) and controlled Iambic-learning were considered. Since a proper set of analysis and analysis process were established. In order to build a new morph lexicon, a copy of the Brown corpus was obtained and sorted (earliest word first). Initial phonetic segment labels were obtained from a computer-readable copy of the Merriam Pocket Dictionary. Beginning with a nascent lexicon containing all found morphs and function words, each word from the Brown corpus was necessarily analyzed. This led to the interactive addition of new morphs and a great deal of experience with morph analysis procedures. This process was accompanied by J. Allen, D. A. Pisacki, with algorithmic and programming support from E. R. Jensen and R. E. Carrell. The process spanned many months, and led to the extension of morph analysis routines to include multiple decompositions and allomorphic selection mechanisms. The process was designed early on with a mind toward using a DEC PDP-9 computer with 244K words of memory and DEC tapes for peripheral storage. Readers familiar with this equipment will have some appreciation of the sheer magnitude of the effort required to build the morph lexicon and acquire the

---

## Our Interpretation

The MITalk system represents a comprehensive, production-ready text-to-speech synthesizer that evolved over two decades (1960s-1980s) through iterative development combining character recognition, linguistic analysis, and speech synthesis. The preface chronicles how initial work on a reading machine for the blind (using analog synthesis) evolved into a sophisticated rule-based system that converts unrestricted English text into intelligible speech by combining morphological decomposition, phonetic rule application, and formant-based synthesis. This work matters for speech synthesis because it established the foundational pipeline architecture (text preprocessing, morphological analysis, letter-to-sound rules, prosody generation, and Klatt synthesizer implementation) that became the standard approach for practical TTS systems.

