# Abstract

## Original Text (Verbatim)

A motor theory of speech perception, initially proposed to account for results of early experiments with synthetic speech, is now extensively revised to accommodate recent findings, and to relate the assumptions of the theory to those that might be made about other perceptual modes. According to the revised theory, phonetic information is perceived in a biologically distinct system, a 'module' specialized to detect the intended gestures of the speaker that are the basis for phonetic categories. Built into the structure of this module is the unique but lawful relationship between the gestures and the acoustic patterns in which they are variously overlapped. In consequence, the module causes perception of phonetic structure without translation from preliminary auditory impressions. Thus, it is comparable to such other modules as the one that enables an animal to localize sound. Peculiar to the phonetic module are the relation between perception and production it incorporates and the fact that it must compete with other modules for the same stimulus variations.

---

## Our Interpretation

The Motor Theory proposes that speech perception is not a purely acoustic process but rather a specialized biological system that recovers the intended articulatory gestures of speakers, explaining how listeners understand speech despite acoustic variability and missing invariant cues. This theory is significant for speech synthesis because it suggests that listeners accept any acoustic pattern that plausibly represents the motor gesturesâ€”validating formant-based synthesis approaches that prioritize phonetically appropriate gesture representations over acoustic exactness. The module-based framework highlights that context-appropriate formant trajectories and proper timing are perceptually more important than reproducing surface acoustics, making it a useful theoretical foundation for understanding synthesis target-setting and evaluating synthesizer naturalness.

---
