This paper presents a cross-lingual machine learning approach to predict grapheme-to-phoneme mappings for unknown Latin-alphabet languages by learning phonotactic patterns from 107 training languages, achieving 88% F1 accuracy on inventory prediction. The key contribution is demonstrating that abstract phonemic context features (extracted from surrounding grapheme articulatory properties like voicing, manner, and place) dramatically outperform raw character context features, and that joint graphical model inference ensures linguistically coherent phoneme inventories. For speech synthesis, the paper shows that phonotactic context is predictive of sound-symbol relationships, and that structured constraints can improve pronunciation modeling accuracy across languages where traditional dictionaries are unavailable.
