This dissertation addresses the gap between canonical dictionary pronunciations and natural surface speech by training neural networks to learn postlexical phonological transformations (flapping, deletion, glottalization, vowel reduction) directly from labeled speech data for individual speakers. The research demonstrates that allophonic variation is largely predictable from phonetic context alone, with the network achieving 87.8% exact match and 98% acceptable pronunciation accuracy, while revealing that /t/ and schwa have the highest entropy (most variable realizations). This work is critical for speech synthesis because it shows how to bridge the lexicon-phonetics gap and identify the most impactful allophony rules (/t/ deletion, flapping, glottalization and vowel fronting) that native speakers expect to hear in natural-sounding speech.