# Pages 160-199 Notes

## Chapters/Sections Covered
- Chapter 12 (continued): The Klatt Formant Synthesizer (pages 148-150)
  - 12.3 Radiation characteristic
- Chapter 13: Some Measures of Intelligibility and Comprehension (pages 151-171)
  - 13.1 Overview
  - 13.2 Phoneme recognition
  - 13.3 Word recognition in sentences
  - 13.4 Comprehension
  - 13.5 General discussion and conclusions
- Chapter 14: Implementation (pages 172-176)
  - 14.1 Conceptual organization
  - 14.2 Development system
  - 14.3 Performance system
  - 14.4 UNIX implementation
  - 14.5 Using the system
- Appendix A: Part-of-speech processor (pages 177-178)
- Appendix B: Klatt symbols (pages 179-180)
- Appendix C: Context-dependent rules for PHONET (pages 181-187+)
  - C.1 Notation
  - C.2 State variables
  - C.3 Phonetic segment classes
  - C.4 Initialization
  - C.5 General rules

## Key Findings
- **Radiation characteristic** is modeled by first-difference of volume velocity: `p(nT) = u(nT) - u(nT-T)` (adds +6 dB/octave slope)
- **SW=0** (normal cascade/parallel): Neither parallel nasal formant nor parallel first formant resonator needed
- **SW=1** (all-parallel): Required for nasalization simulation
- **Modified Rhyme Test results**: 6.9% overall error rate (vs 7.6% for earlier Haskins evaluation)
  - Initial consonants: 4.6% errors
  - Final consonants: 9.3% errors
  - Nasals in final position: 27.6% error rate (worst)
  - Fricatives DH and TH: very high error rates
- **Word recognition in sentences**:
  - Harvard sentences: 93.2% correct
  - Haskins anomalous sentences: 78.7% correct
- **Comprehension test**: 77.2% reading vs 70.3% listening (statistically significant p < .05)
- **Learning effect**: Performance improves from 55% to 90% correct after 200 synthetic sentences exposure
- **Speaking rate**: 180 words/minute used for evaluation (matches normal conversational rate)
- **MITalk pipeline architecture**: FORMAT -> DECOMP -> PARSER -> SOUND1 -> COEWAV

## Equations Found

### Radiation Characteristic (Eq. 8, p.150)
$$p(nT) = u(nT) - u(nT-T)$$
Where:
- $p(nT)$ = sound pressure at time nT
- $u(nT)$ = lip-plus-nose volume velocity
- $T$ = sampling period

### Rule Notation for PHONET (p.181)
$$variable \leftarrow value / pattern$$
Where:
- $\leftarrow$ means "gets set to"
- $\uparrow$ means "increase by"
- $\downarrow$ means "decrease by"

Example: `Target[avc] ↓ 30 / [+fricative, +voiced][-vowel]`
(Decrease Target avc by 30dB if current segment is voiced fricative and next is non-vocalic)

## Parameters Found

| Name | Symbol | Units | Default | Range | Notes |
|------|--------|-------|---------|-------|-------|
| Cumdur | Cumdur[av..f0] | msec | - | - | Cumulative time from utterance start to segment start |
| Segdur | Segdur[av..f0] | msec | - | - | Duration of current segment per parameter |
| Mintime | Mintime[av..f0] | msec | - | - | Minimum time for backward smoothing (corresponds to t0) |
| Trantype | Trantype[av..f0] | enum | SETSMO | - | Transition type (SETSMO, DISSMO) |
| Target | Target[av..f0] | dB/Hz | - | - | Target values at Segdur+Cumdur |
| Diptar | Diptar[f1..f3] | Hz | - | - | Diphthong target values |
| Oldval | Oldval[av..f0] | dB/Hz | - | - | Value at end of previous segment |
| Nextar | Nextar[av..f0] | dB/Hz | - | - | Target value for next segment |
| Tcf | Tcf[av..f0] | msec | - | - | Forward smoothing duration from Cumdur |
| Tcb | Tcb[av..f0] | msec | - | - | Backward smoothing duration (limited by Mintime) |
| Bper | Bper[av..f0] | % | 75 (f0) | - | Percent movement from locus toward target in CV/VC |
| Bvf | Bvf[av..f0] | dB/Hz | - | - | Desired value immediately after Cumdur |
| Bvb | Bvb[av..f0] | dB/Hz | - | - | Desired value immediately before Cumdur |
| Buramp | - | dB | 57 | - | Burst amplitude |
| Aspamp | - | dB | 51 | - | Aspiration amplitude |
| Aspdux | - | msec | 30 | - | Aspiration duration into pause |
| Aspam1 | - | dB | - | - | Aspiration amplitude (alternate) |
| Target[fnz] | - | Hz | 250 | - | Nasal zero frequency target |
| Target[an] | - | dB | 0 | - | Nasal amplitude target |

## Rules/Algorithms

### Part-of-Speech Assignment Algorithm (Appendix A, p.177-178)
```
IF there is no decomposition
  THEN assign (NOUN (NUM SING)), (VERB (INF TR) (PL TR)), (ADJ)
ELSEIF last morph is not a suffix
  THEN IF first morph is a verb prefix
    THEN assign (VERB (INF TR) (PL TR))
  ELSEIF first morph is A
    THEN assign (ADJ), (ADV)
  ELSE assign from last morph
ELSEIF last morph is ING
  THEN assign (VERBING)
ELSEIF last morph is ED
  THEN assign (VERBEN), (VERB (SING TR) (PL TR))
ELSEIF last morph is S or ES
  THEN IF next morph is not a suffix AND first morph is a verb prefix
    THEN assign (VERB (SING TR))
  ELSE IF next morph is a verb
    THEN assign (VERB (SING TR))
  IF next morph is a NOUN, ADJ, INTG, ER, or ING
    THEN assign (NOUN (NUM PL))
  IF next morph is an ORD AND next morph is not SECOND
    THEN assign (ORD (NUM PL))
  IF there is no assignment
    THEN assign (NOUN (NUM PL))
ELSEIF last morph is ER
  THEN IF next morph is an ADV THEN assign (ADV)
       IF next morph is an ADJ THEN assign (ADJ)
       IF next morph is a NOUN or VERB THEN assign (NOUN (NUM SING))
ELSEIF last morph is S'
  THEN assign (NOUN (POSS TR))
ELSEIF last morph is 'S
  THEN IF next morph is a NOUN
    THEN assign (NOUN (POSS TR)), copy (NOUN (CONTR TR))
  ELSEIF next morph is a PRN
    THEN copy (PRN (CONTR TR))
      IF next morph has feature (PRNADJ TR)
        THEN copy (PRN (CASE POSS))
ELSEIF last morph is N'T
  THEN IF next morph is NEED
    THEN assign (MOD (AUX A) (NOT TR))
  ELSEIF next morph is a BE
    THEN copy (BE (NOT TR))
  ELSEIF next morph is a HAVE
    THEN copy (HAVE (NOT TR))
  ELSEIF next morph is a MOD
    THEN copy (MOD (NOT TR))
ELSEIF last morph is 'VE AND next morph is a MOD
  THEN copy (MOD (CONTR TR))
ELSEIF last morph is 'VE, 'D, 'LL, or 'RE
  THEN IF next morph is S
    THEN assign (NOUN (NUM PL) (CONTR TR))
  ELSEIF next morph is a NOUN
    THEN copy (NOUN (CONTR TR))
  ELSEIF next morph is a PRN
    THEN copy (PRN (CONTR TR))
ELSE assign part of speech from rightmost morph
```

### Manner Class Initialization (p.185)
```
Manner <- vowel / [+vowel]
ELSE Manner <- stop / [+stop]
ELSE Manner <- fricative / [+fricative]
ELSE Manner <- sonorant
```

### General Rules Examples (p.185)
- `Bper[f0] <- 75` (F0 boundary percent = 75%)
- Suppress amplitude smoothing after plosive: `Mintime[af] <- Cumdur[af] / [+plosive]_`
- Discontinuous transition out of unvoiced: `Trantype[f0, av] <- DISSMO / [-voiced]_`
- Breathy offset into pause: `Aspdux <- 30, Oldval[avc] ↑ 6, Aspam1 <- Aspamp / [-SIL][+SIL]`

## Figures of Interest
- **Fig 12-12 (p.148):** Preemphasized output spectra comparing cascade vs parallel models for IY, AA, UW vowels and uniform tract - shows cascade produces smoother spectra
- **Fig 12-13 (p.149):** Spectra from two different parallel synthesis configurations (+-+ vs +++) - demonstrates effect of different resonator combinations
- **Fig 12-14 (p.150):** Transfer function of radiation characteristic - shows +6dB/octave rise from 0-5kHz
- **Fig 13-1 (p.154):** Average percent errors across manner classes - Nasals worst (22-27%), Stops best (~2%)
- **Fig 13-2 (p.155):** Distribution of errors and perceptual confusions - detailed breakdown by phoneme
- **Fig 13-3 (p.165):** Comprehension scores: Reading 77.2% vs Listening 70.3%
- **Fig 14-1 (p.176):** Sample MITalk session showing full pipeline from text input through phonetic output

## Tables of Interest
- **Table 13-1 (p.163):** Characteristics of 15 test passages for comprehension (212-327 words, 56-135 seconds duration)
- **Table B-1 (p.179):** Complete Klatt symbol inventory for phonetic segments (vowels, consonants, affricates)
- **Table B-2 (p.180):** Klatt symbols for nonsegmental units (stress, boundaries, syntactic structure)
- **Table C-1 (p.186):** Parameter targets for NON-VOCALIC segments (complete table with av, avc, asp, af, a2-a6, ab, f1-f4, b1-b3)
- **Table C-2 (p.187):** Parameter targets for VOCALIC segments (vowels with formant frequencies and bandwidths)

## Quotes Worth Preserving

> "The sound pressure measured directly in front of and about a meter from the lips is proportional to the temporal derivative of the lip-plus-nose volume velocity, and inversely proportional to r, the distance from the lips (Fant, 1960)." (p.150)

> "For the most part, the intelligibility of the speech produced by the current version of the text-to-speech system is very high. The overall error rate of 6.9 percent is slightly lower than the error rate of 7.6 percent obtained in the earlier Haskins evaluation using the Modified Rhyme Test." (p.155)

> "Substantial learning effects occur with synthetic speech. Even after an initial period of exposure, recognition performance continues to improve... performance increased from 55 percent to 90 percent correct after the presentation of only 200 synthetic sentences over a two-week period." (p.156)

> "The overall conceptual organization of the MITalk system can be viewed on two levels. At the highest level, the system is viewed as an analysis/synthesis system. It is based on the premise that in order to transform an input textual representation (as a string of ASCII characters) to an output synthesized speech waveform, it is necessary to first analyze the text into an underlying abstract linguistic representation which can then be used as the initial basis for synthesizing the waveform." (p.172)

> "In the future, one can conceive of the entire MITalk system implemented on a single integrated-circuit wafer, or in a small set of chips." (p.174)

## Implementation Notes

### MITalk Pipeline Modules
1. **FORMAT** - Text normalization (abbreviations, symbols, numbers to words)
2. **DECOMP** - Morphological decomposition via morph lexicon
3. **PARSER** - Syntactic parsing (noun groups, verb groups, prepositional phrases)
4. **SOUND1** - Letter-to-sound rules, produces phonetic transcription
5. **COEWAV** - Klatt synthesizer, produces waveform

### State Variable Array Indexing
Parameters indexed as `variable[parameter]` where parameter can be:
- `av..f0` = all parameters from av through f0
- `p1, p2` = specific parameters p1 and p2
- `p1..p2` = range from p1 through p2

### Phonetic Segment Classes (for rule matching)
| Class | Members |
|-------|---------|
| affricate | CH, JJ |
| alveolar | DD, DX, EN, NN, SS, TQ, TT, ZZ |
| aspseg | HH, HX, WH |
| dental | DH, TH |
| diphthong | AE, AO, AW, AXR, AY, EH, EXR, EY, IH, IXR, IY, OW, OXR, OY, UH, UW, YU |
| f2back | IY, YU, YY |
| fricative | DH, FF, SS, SH, TH, VV, ZH, ZZ |
| front | AE, EH, EXR, EY, IH, IX, IXR, IY, YU |
| glottal | HH, HX, QQ, SIL |
| high | IH, IX, IXR, IY, UH, UW, UXR, WH, WW, YU, YY |
| labial | BB, EM, FF, MM, PP, VV, WW, WH |
| lateral | EL, LL, LX |
| lax | AE, AO, AX, AXP, EH, IH, IX, UH |
| liqglide | EL, LL, LX, RR, RX, WH, WW, YY |
| low | AA, AE, AO, AW, AXR, AY |
| nasal | EM, EN, MM, NN, NG |
| palatal | CH, JJ, SH, YY, ZH |
| palvel | GP, KP |
| plosive | BB, CH, DD, GG, GP, JJ, KK, KP, PP, TQ, TT |
| retro | ER, RR, RX |
| rglide | AXR, EXR, IXR, OXR, UXR |
| round | AO, OW, OXR, OY, UH, UW, WH, WW, YU |
| schwa | AX, IX |
| sonorant | AA, AE, AH, AO, AW, AX, AXR, AY, EH, EL, EM, EN, ER, EXR, EY, HH, HX, IH, IX, IXR, IY, LL, LX, MM, NG, NN, OW, OXR, OY, RR, RX, UH, UW, UXR, WH, WW, YU, YY |
| stop | BB, CH, DD, DX, EM, EN, GG, GP, JJ, KK, KP, MM, NG, NN, PP, QQ, TQ, TT |
| syllabic | AA, AE, AH, AO, AW, AX, AXR, AY, EH, EL, EM, EN, ER, EXR, EY, IH, IX, IXR, IY, OW, OXR, OY, UH, UW, UXR, YU |
| velar | GG, KK, NG |
| voiced | AA, AE, AH, AO, AW, AX, AXR, AY, BB, DD, DH, DX, EH, EL, EM, EN, ER, EXR, EY, GG, GP, HX, IH, IX, IXR, IY, JJ, LL, LX, MM, NG, NN, OW, OXR, OY, QQ, RR, RX, TQ, UH, UW, UXR, VV, WH, WW, YU, YY, ZH, ZZ |
| vowel | AA, AE, AH, AO, AW, AX, AXR, AY, EH, ER, EXR, EY, IH, IX, IXR, IY, OW, OXR, OY, UH, UW, UXR, YU |
| wglide | AW, OW, UW, YU |
| yglide | AY, EY, IY, OY |

### Key Default Values
- `Bper[f0] = 75` (75% movement toward target for F0)
- `Buramp = 57` dB (burst amplitude)
- `Aspamp = 51` dB (aspiration amplitude)
- `Target[fnz] = 250` Hz (nasal zero)
- `Target[an] = 0` dB (nasal amplitude)
- `Aspdux = 30` ms (aspiration duration into pause)

### Non-Vocalic Segment Parameters (Table C-1 excerpt)
| Seg | av | avc | asp | af | a2 | a3 | a4 | a5 | a6 | ab | f1 | f2 | f3 | f4 | b1 | b2 | b3 |
|-----|----|----|-----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|
| AXP | 57 | 60 | 0 | 0 | 60 | 60 | 60 | 60 | 60 | 0 | 430 | 1500 | 2500 | 3300 | 120 | 60 | 120 |
| BB | 0 | 54 | 0 | 0 | 0 | 0 | 0 | 0 | 72 | 0 | 200 | 900 | 2100 | 3300 | 65 | 90 | 125 |
| CH | 0 | 0 | 0 | 60 | 75 | 70 | 70 | 0 | 0 | 300 | 1700 | 2400 | 3300 | 200 | 110 | 270 |
| DD | 0 | 54 | 0 | 0 | 0 | 0 | 50 | 82 | 0 | 200 | 1400 | 2700 | 3300 | 70 | 115 | 180 |
| SIL | 0 | 0 | 0 | 60 | 60 | 60 | 60 | 60 | 0 | 300 | 1400 | 2400 | 3300 | 200 | 140 | 250 |
| TT | 0 | 0 | 0 | 0 | 0 | 0 | 50 | 82 | 0 | 300 | 1400 | 2700 | 3300 | 30 | 180 | 220 |

### Vocalic Segment Parameters (Table C-2 excerpt)
| Seg | av | avc | f1 | f2 | f3 | f4 | b1 | b2 | b3 |
|-----|----|----|----|----|----|----|----|----|----|
| AA | 57 | 57 | 700 | 1220 | 2600 | 3300 | 130 | 70 | 160 |
| AE | 57 | 57 | 620/650 | 1660/1490 | 2430/2470 | 3300 | 70 | 130 | 300 |
| IY | 60 | 60 | 310/290 | 2200/2070 | 2960/2980 | 3300 | 50 | 200 | 400 |
| UW | 64 | 64 | 350/320 | 1250/900 | 2200 | 3300 | 65 | 110 | 140 |
| AX | 60 | 60 | 550/520 | 1260/1400 | 2470/1650 | 3300 | 80 | 50 | 140 |

(Multiple f1/f2/f3 values indicate diphthong targets)

## References to Other Chapters
- Figure 11-6 referenced for timing parameters (t0, t1, t2) - see Chapter 11 on prosody
- Figure 12-6 referenced for synthesizer block diagram - see earlier in Chapter 12
- Chapter 6 referenced for lexical stress rules notation
- Tables C-3, C-4 referenced for Tcf and Bper values (not in this chunk)
- Appendixes D, E, F, G referenced for test materials
