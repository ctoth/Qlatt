# Pages 040-079 Notes

## Chapters/Sections Covered
- **Section 2.1** Harmonic Estimation (continued from earlier chunk)
- **Section 2.2** Harmonic Trajectories (Sinusoidal Models)
  - 2.2.1 Trajectories estimation
  - 2.2.2 Trajectories transformation (Time-scaling, Timbre scaling, Pitch transposition)
  - 2.2.3 Shape Invariance
  - 2.2.4 Pulse Sequence Irregularities (Roughness, Growl)
  - 2.2.5 Synthesis of harmonic trajectories

## Key Findings

### Harmonic Estimation (pp. 41-45)
- Time-varying sinusoids cause spectral leakage in STFT - both amplitude and phase shapes differ from window transform
- Amplitude modulations affect mostly phase shape; frequency modulations affect both amplitude and phase shapes
- Blackman-Harris 92dB window used for analysis (0.5 seconds long)
- For voice signals, harmonics clearly correspond to spectral peaks when analysis window is centered at voice pulse onset

### Harmonic Trajectories (pp. 46-48)
- Voice signals can be modeled as sum of time-varying quasi-sinusoidal harmonics
- Each harmonic has time-varying frequency, amplitude, and phase
- Analysis uses sliding square window of length L+1 at equidistant time instants (frames)
- Harmonic trajectories connect parameters across consecutive frames (also called "partial tracks")

### Trajectories Estimation (pp. 47-48)
- McAulay and Quatieri (1986): simple continuation algorithm based on closest spectral peak
- Serra (1989): added "frequency guides" from surrounding peaks and fundamental frequency
- Garcia (1992): Hidden Markov models for tracking partials
- Peeters (2001): non-stationary sinusoid model with linearly varying amplitude and frequency

### Trajectories Transformation (pp. 49-51)
- **Time-scaling**: Maps input time t to output time t' via transformation function
- **Timbre scaling**: Modifies spectral amplitude envelope; T_timbre > 1 = frequency domain stretching (longer vocal tract); T_timbre < 1 = compression
- **Pitch transposition**: Linear scaling of frequency axis by factor T_pitch; requires simultaneous amplitude correction to preserve timbre

### Shape Invariance (pp. 51-56)
- Critical concept: waveform shape around glottal pulse onsets is roughly independent of pitch
- Shape depends on vocal tract impulse response, not fundamental frequency
- Proper phase coherence at pulse onsets essential for natural sound
- **MFPA Algorithm (Maximally Flat Phase Alignment)**: estimates glottal pulse onsets from harmonic phases
  - When analysis window centered at pulse onset, phase spectrum is nearly flat under each formant
  - Algorithm finds time-shift that minimizes phase differences between harmonics

### MFPA Algorithm Steps (p. 56)
1. Define several fundamental phase candidates in interval [-pi, pi]
2. For each candidate, apply time-shift to each harmonic peak, rotating phases
3. Compute sum of rotated phase differences (princarg function)
4. Find phi_min that approximately centers window at voice pulse onset
5. Estimate closest pulse onset time

### Pulse Onset Sequence Optimization (pp. 59-61)
- Dynamic programming approach (Viterbi-inspired) to find best pulse sequence Q_K
- Fundamental frequency error: relative difference between pulse duration and average period
- Handles voiced-to-unvoiced (VU) and unvoiced-to-voiced (UV) transitions
- Error accumulation with transition error to choose best previous onset

### Phase Unwrapping and Correction (pp. 63-65)
- Phase unwrapping needed when computing transformed MFPA alignment
- Phase correction theta_h,m added to handle period discontinuities
- Smoothing correction decays to zero by adding/subtracting theta_correc (0.1 radians used)

### MFPA Evaluation Results (pp. 66-74)
- Tested on Keele Pitch Database (10 speakers, 22kHz)
- For e_LM errors: 76.27% within -0.1 to 0.1 (10% of period), 89.11% within -0.15 to 0.15
- For e_ML errors: 78.31% within -0.1 to 0.1, 90.85% within -0.15 to 0.15
- Mean errors: 0.032 (e_LM) and -0.028 (e_ML)
- 89.11% of MFPA predictions within 15% of period

### Pulse Sequence Irregularities (pp. 75-79)
- **Roughness**: Cycle-to-cycle variations in F0 (jitter) and amplitude (shimmer)
- Algorithm transposes signal down by 1/N, delays with random jitter, overlaps scaled copies
- Delay for each shifted version: Delta_i = iT_0 + X_i (T_0 = period, X_i = random variable)
- Jitter variance ~3% of input period, shimmer variance ~3dB

### Growl Transformation (pp. 77-79)
- Growl comes from simultaneous vibrations of vocal folds and aryepiglottic folds
- Adds sub-harmonics to spectrum at frequencies f_0 * (h + (k+1)/4) for integer h, k
- Sub-harmonic phases: phi_h^k = phi_h + (2*pi/(N+1)) * (k+1) * p
- Algorithm uses automatic growl control based on F0 derivatives and energy

### Synthesis of Harmonic Trajectories (p. 80)
- Synthesis equation: s'(n) = sum over frames of frame signals with overlap windows
- Frame signal: s'_m(n) = sum of sinusoids with interpolated parameters
- Sinusoid function chi computes discrete time-domain signal from amplitude, frequency, phase

## Equations Found

### Signal as Sum of Harmonics (p. 46)
$$s(t) = \sum_{h=0}^{H-1} a_h(t) \cos(\phi_h(t))$$
- $a_h(t)$: amplitude of harmonic h at time t
- $\phi_h(t)$: instantaneous phase of harmonic h

### Continuous Phase from Frequency (Eq. 2.19, p. 46)
$$s(t) = \sum_{h=0}^{H-1} a_h(t) \cos\left(2\pi \int_0^t f_h(\tau) d\tau + \phi_{0,h}\right)$$
- $f_h(\tau)$: instantaneous frequency
- $\phi_{0,h}$: initial phase

### Discrete Signal (Eq. 2.20, p. 46)
$$s(n) = \sum_{h=0}^{H-1} a_h(nT_s) \cos\left(2\pi \sum_{k=0}^{n-1} f_h(kT_s)T_s + \phi_{0,h}\right)$$
- $T_s$: sampling period

### Frame Signal (Eq. 2.22, p. 46)
$$s_m(n) = \sum_{h=0}^{H-1} a_{h,m} \cos(2\pi f_{h,m} n T_s + \phi_{0,h,m})$$
- Assuming stationarity within m-th frame

### Signal Approximation via Overlap-Add (Eq. 2.23, p. 46)
$$s(n) \approx \sum_{m=0}^{M-1} s_m\left(n - m\frac{\Delta_t}{T_s}\right) \cdot w_{ov}\left(n - m\frac{\Delta_t}{T_s}\right)$$
- $w_{ov}$: overlapping window
- $\Delta_t$: hop size

### Timbre Scaling (Eq. 2.25, p. 49)
$$H'_{harm}(f) = H_{harm}(\bar{T}_{timbre}^{-1}(f))$$
- $H_{harm}$: spectral amplitude envelope
- $\bar{T}_{timbre}$: timbre mapping function

### Amplitude After Timbre Scaling (Eq. 2.26, p. 49)
$$a'_h = H'_{harm}(f_h) = H_{harm}(\bar{T}_{timbre}^{-1}(f_h))$$

### Pitch Transposition with Timbre Preservation (Eq. 2.27, p. 50)
$$f'_h = T_{pitch} \cdot f_h$$
$$a'_h = H_{harm}(T_{pitch} \cdot f_h)$$

### Phase Propagation (Eq. 2.28, p. 50)
$$\phi'(t) = \phi'(0) + 2\pi \int_0^t f'(\tau) d\tau$$

### Linear Phase Interpolation (Eq. 2.29, p. 51)
$$\phi'_m(t) = \phi'_{m-1}(t_{m-1}) + 2\pi \frac{f_{m-1} + f_m}{2} \Delta_t$$
- For $t_{m-1} \leq t \leq t_m$

### HMM Transition Probability for Trajectory Estimation (Eq. 2.24, p. 48)
$$prob_{trans}\left([k'_{l,m-1}, k'_{l,m+1}] | [k_{l,m}, k'_{l,m+1}]\right) = e^{-\frac{(\Delta f'_{l,m-1} - \Delta f'_{l,m})^2}{\sigma_{f'}^2}} e^{-\frac{(\Delta a'_{l,m-1} - \Delta a'_{l,m})^2}{\sigma_{a'}^2}}$$

### Fundamental Frequency Error (Eq. 2.30, p. 59)
$$E_{f_0}(Q_K) = \sum_{i=1}^{q-1} e_{f_0}(k_i, k_{i-1}) = \sum_{i=1}^{q-1} \frac{\left|(\hat{t}_{k_i} - \hat{t}_{k_{i-1}}) - \bar{T}_i\right|}{\bar{T}_i}$$
- $\hat{t}_k$: estimated pulse onset time
- $\bar{T}_i$: average period duration

### Average Period Duration (Eq. 2.31, p. 59)
$$\bar{T}_i = \frac{1}{(m_e - m_b + 1)} \sum_{m=m_b}^{m_e} \frac{1}{f_{0,m}}$$
- $m_b$, $m_e$: indices of closest voiced frames

### Expanded Pulse Candidates (Eq. 2.32, p. 60)
$$P_{expanded} = \{\hat{t}_{i,m}\} \quad \forall i \in \{0, 1, ... N_p - 1\}, \forall m \text{ having } f_{0,m} > 0$$
$$\hat{t}_m = t_m + \frac{princarg(\theta_{min} - \theta_{0,0})}{2\pi f_{0,m}}$$

### MFPA Onset Candidate Error (Eq. 2.33, p. 60)
$$E_{MFPA}(Q_K) = \sum_{i=0}^{q-1} e_{MFPA}(k_i)$$

### Accumulated Error with Transition (Eq. 2.35, p. 61)
$$e_{acum}(k_i) = e_{acum}(k_{i-1}) + e_{MFPA}(k_i, k_{i-1}) + e_{f_0}(k_i)$$

### MFPA Phase Alignment (Eq. 2.36, p. 62)
$$\phi_{0,m}^{mfpa}(h) = \phi_{0,h,m}^{mfpa} = \phi_{0,h,m} + 2\pi f_{h,m}(\hat{t}_{k_i} - t_m)$$

### Synthesis Phase Computation (Eq. 2.37, p. 63)
$$\phi'_{0,h,m} = \phi'^{mfpa}_{0,h,m} + \frac{f'_{h,m}}{f'_{0,m}} princarg(\phi'_{0,0,m} - \phi'^{mfpa}_{0,0,m})$$

### Phase Unwrapping (Eq. 2.38, p. 63)
$$\phi_h^{uw} = \phi_{h-1}^{uw} + princarg(\phi_h - \phi_{h-1})$$

### Phase Correction (Eq. 2.39, p. 64)
$$\theta_{h,m} = \begin{cases} -2\pi & \text{if } x \geq \pi \\ 0 & \text{if } -\pi \leq x < \pi \\ 2\pi & \text{if } x < -\pi \end{cases}$$
$$x = princarg(\phi_{h,m} - \phi_{h-1,m}) - princarg(\phi_{h,m-1} - \phi_{h-1,m-1})$$

### Smoothed Phase Correction (Eq. 2.40, p. 64)
$$\tilde{\theta}_{h,m} = \tilde{\theta}_{h,m-1} - sign(\tilde{\theta}_{h,m-1}) \cdot min(|\tilde{\theta}_{h,m-1}|, \theta_{correc}) + \theta_{h,m}$$
- $\theta_{correc} = 0.1$ radians used in experiments

### Laryngograph-to-MFPA Error (Eq. 2.41, p. 66)
$$e_{LM}(l) = \frac{t_l^{LG} - \hat{t}_{k_c}}{f_0^{-1}(t_l^{LG})}$$
- Temporal distance normalized by fundamental period

### MFPA-to-Laryngograph Error (Eq. 2.42, p. 66)
$$e_{ML}(k) = \frac{\hat{t}_k - t_{l_c}^{LG}}{f_0^{-1}(\hat{t}_k)}$$

### Roughness Delay (Eq. 2.43, p. 75)
$$\Delta_i = iT_0 + X_i$$
- $T_0$: fundamental period
- $X_i$: zero-mean random variable (jitter)

### Rough Phase Correction (Eq. 2.44, p. 76)
$$\phi_r = \phi_g + 2\pi f_g \left(\frac{f_r}{f_g} - 1\right) \Delta_t$$
- $r$: sinusoid index
- $g$: index of corresponding harmonic

### Sub-harmonic Phase for Growl (Eq. 2.45, p. 78)
$$\phi_h^k = \phi_h + \frac{2\pi}{N+1}(k+1)p$$
- $k = 0, 1, 2$ and $p = 0, 1, 2, 3$ (inner period index)
- $N$: number of sub-harmonics

### Synthesis Signal (Eq. 2.46, p. 79)
$$s'(n) = \sum_{m=0}^{M'-1} s'_m\left(n - m\frac{\Delta'_t}{T'_s}\right) \cdot w'_{ov}\left(n - m\frac{\Delta'_t}{T'_s}\right)$$

### Synthesis Frame Signal (Eq. 2.47, p. 80)
$$s'_m(n) = \sum_{h=0}^{H'-1} \chi(a'_{h,m}, f'_{h,m}, \phi'_{0,h,m})$$

### Harmonics as Stationary Sinusoids (Eq. 2.48, p. 80)
$$s'_m(n) = \sum_{h=0}^{H'-1} \chi(a'_{h,m}, f'_{h,m}, \phi'_{0,h,m}) = \sum_{h=0}^{H'-1} a'_{h,m} \cos(2\pi f'_{h,m} n T'_s + \phi'_{0,h,m})$$

## Parameters Found

| Name | Symbol | Units | Value/Range | Notes |
|------|--------|-------|-------------|-------|
| Analysis window type | - | - | Blackman-Harris 92dB | High sidelobe suppression |
| Analysis window length | - | seconds | 0.5 | Covers multiple periods |
| MFPA phase candidates | - | count | ~80 | Reasonable size for interval [-pi, pi] |
| Minimum ratio alpha | - | - | 0.75 | For real-time pulse sequence |
| Phase correction decay | theta_correc | radians | 0.1 | For smoothing frame corrections |
| Jitter variance | - | % of period | 3% | For roughness transformation |
| Shimmer variance | - | dB | 3 | For roughness transformation |
| Sub-harmonics for growl | N | count | 3 | Typical for growl effect |
| Sub-harmonic frequency band | - | Hz | [f_0, 8000] | For growl sub-harmonics |

## Rules/Algorithms

### MFPA Algorithm (Maximally Flat Phase Alignment) - pp. 55-56
1. Define several fundamental phase candidates phi_0 in interval [-pi, pi]
2. For each candidate, apply corresponding time-shift Delta_t to each harmonic peak
3. Phase of each harmonic h rotates as: phi_tilde_0,h = phi_0,h + 2*pi*f_h*Delta_t
4. Compute sum of rotated phase differences: phi_diff = sum|princarg(phi_tilde_0,h+1 - phi_tilde_0,h)|
5. Find phi_min (minimum of phi_diff) - this corresponds to window approximately centered at voice pulse onset
6. Estimate pulse onset time: t_MFPA = t_frame + princarg(phi_min - phi_0,0) / (2*pi*f_0)

### Dynamic Programming for Best Pulse Sequence - p. 61
1. Initialize accumulated error e_acum(0) = 0, k_0 = 0
2. Add onset at beginning if t_0 = 0 (if not already exists)
3. For each onset k_i, choose previous k_{i-1} that minimizes: e_acum(k_{i-1}) + e_MFPA(k_i, k_{i-1})
4. Add onset at signal end if needed: k_{q-1} = p-1

### Transformed Harmonic Phase Synthesis - p. 62
a) SYNTHESIS FUNDAMENTAL PHASE: Propagate synthesis fundamental phase phi'_0,0,m by any appropriate method (e.g., linear frequency assumption)
b) MFPA ALIGNMENT: Calculate closest pulse onset t_k_i and compute harmonic phases from time-shift: phi_0,m^mfpa(h) = phi_0,h,m + 2*pi*f_h,m*(t_k_i - t_m)
c) TRANSFORMED MFPA ALIGNMENT: Compute transformed phase alignment by discrete/interpolation mapping
d) SYNTHESIS HARMONIC PHASES: Apply time-shift difference to get final synthesis phases

### Roughness Transformation - pp. 75-76
1. Take original voice signal, transpose down by factor T_pitch = 1/N
2. Create N delayed copies with random delays: Delta_i = i*T_0 + X_i
3. Scale each delayed version by random gain Y_i (unity mean)
4. Overlap all versions to create irregular pulse pattern
5. For real-time: add sub-harmonics in frequency domain at 1.5*f_0, 2.5*f_0, etc.

### Growl Transformation - pp. 77-79
1. Identify fundamental period and inner periods (typically 4)
2. Add sub-harmonics at frequencies f_0*(h + (k+1)/4) for h in [0, H-1], k in {0,1,2}
3. Set sub-harmonic magnitudes based on spectral envelope (closer to harmonic = higher amplitude)
4. Set sub-harmonic phases with N+1 period advance: phi_h^k = phi_h + (2*pi/(N+1))*(k+1)*p
5. Apply automatic growl control based on F0 derivatives and energy

## Figures of Interest

- **Table 2.1 (p. 41):** Relationship between spectral shape and first/second order sinusoidal amplitude and frequency functions - shows how time-varying parameters affect STFT
- **Fig 2.9 (p. 42):** STFT of non-stationary sinusoids with varying amplitude - shows spectral leakage effects
- **Fig 2.10 (p. 43):** STFT with power-law amplitude and frequency variations
- **Fig 2.13 (p. 45):** Waveform and spectrum of sung /a/ vowel showing harmonics as spectral peaks
- **Fig 2.14 (p. 47):** Harmonic trajectory estimation framework - STFT -> peak detection -> parameter estimation -> trajectory estimation
- **Fig 2.15 (p. 48):** Harmonic trajectories of sung "gin" showing vibrato in time-frequency plane
- **Fig 2.16 (p. 49):** Time-scaling in constant frame-rate framework - parameter interpolation
- **Fig 2.17 (p. 50):** Pitch transposition showing frequency and amplitude modification
- **Fig 2.18 (p. 51):** Formant to spectral-phase relation - phase is flat under formants at pulse onset
- **Fig 2.19 (p. 53):** Shape invariance - waveform shape around pulse onsets independent of pitch
- **Fig 2.20 (p. 53):** Effect of amplitude/phase randomization on waveform shape
- **Fig 2.21 (p. 54):** Shape variant vs invariant pitch transposition comparison
- **Fig 2.22 (p. 54):** Octave-down transposition with/without voice pulse onset alignment
- **Fig 2.23 (p. 55):** Window centering effects on spectrum - doubled phase adds roughness
- **Fig 2.24 (p. 56):** MFPA phase difference function - minimum indicates pulse onset
- **Fig 2.25 (p. 57):** Spectral envelopes used for MFPA synthetic example
- **Fig 2.26-2.27 (p. 58):** MFPA estimation results showing harmonic amplitude/phase vs frequency
- **Fig 2.28 (p. 59):** MFPA analysis of "I can be" utterance with pulse onsets and phi_min
- **Fig 2.29 (p. 60):** Candidate position function within pulse period
- **Fig 2.30 (p. 61):** Dynamic programming illustration for finding optimal pulse subset Q_K
- **Fig 2.31 (p. 62):** MFPA analysis of speech recording with voiced/unvoiced segmentation
- **Fig 2.32 (p. 63):** Voice pulse onsets detected by MFPA in growl utterance
- **Fig 2.33 (p. 64):** MFPA preservation framework showing phase interpolation and time-shift
- **Fig 2.34 (p. 65):** Phase unwrapping problem - different 2*pi periods added across frames
- **Fig 2.35 (p. 67):** MFPA with/without real-time adaptation compared to laryngograph
- **Fig 2.36-2.39 (pp. 69-72):** Voice pulse onsets computed by MFPA in various utterances
- **Fig 2.40-2.42 (pp. 73-75):** Histograms of e_LM and e_ML errors from Keele Pitch Database
- **Fig 2.43 (p. 76):** Rough transformation algorithm block diagram
- **Fig 2.44 (p. 77):** Simplified rough transformation in frequency domain
- **Fig 2.45 (p. 78):** Growl waveform and spectrum showing sub-harmonics
- **Fig 2.46 (p. 79):** Growl transformation - phase patterns for consecutive periods
- **Fig 2.47 (p. 80):** Harmonic trajectory synthesis - time-frequency plane to overlapped frames

## Quotes Worth Preserving

> "The shape of the time-domain waveform signal around the impulse onsets is roughly independent of the pitch, but it depends mostly on the impulse response of the vocal tract." (p. 51-52)

> "Phase is perceptually significant and requires special attention for producing natural sounding transformations." (p. 51)

> "Not preserving such relationship results not only in a loss of presence and definition of the voice, but also makes it sound artificial, especially in the case of low pitches and also during transitions." (p. 51)

> "MFPA algorithm generally obtains good enough approximations of the glottal closure instants (GCIs) as to effectively minimize smearing and roughness in processed voiced signals." (p. 68)

> "For the 76.27 percent of laryngograph peaks, the closest MFPA onset is closer than a ten percent of the period. Moreover, for the 89.11 percent the closest MFPA prediction is within a fifteen percent of the period." (p. 74-75)

> "Roughness in voice can come from different pathologies such as biphonia, or diplophonia, and can combine with many other voice tags such as hoarse or creaky." (p. 75)

> "Growl comes from simultaneous vibrations of the vocal folds and supra glottal structures of the larynx. The vocals folds vibrate half periodically to the aryepiglottic fold vibration generating sub-harmonics." (p. 77)

## Implementation Notes

### For Klatt Synthesizer Relevance
- The MFPA algorithm is highly relevant for accurate glottal pulse timing in synthesis
- Shape invariance concept crucial: waveform shape around pulse onset should be preserved during pitch modification
- Phase relationships between harmonics at formant frequencies are perceptually important
- Phase should be flat under each formant resonance when window is centered at pulse onset

### Data Structures
- **Harmonic trajectory**: Array of (amplitude, frequency, phase) tuples indexed by [harmonic_index][frame_index]
- **Pulse onset sequence**: Array of time instants representing detected/estimated glottal closures
- **Synthesis parameters**: Per-frame parameters (a'_h,m, f'_h,m, phi'_0,h,m) for each harmonic

### Edge Cases
- Unvoiced sections: MFPA relies on fundamental frequency, not applicable to unvoiced regions
- Low F0 utterances: May have weak fundamental energy, affecting MFPA reliability
- Voiced-to-unvoiced transitions: Special handling needed in pulse sequence optimization
- Growl with high amplitude modulation: May affect sub-harmonic detection

### Key Implementation Considerations
1. **princarg function**: x - 2*pi*floor(x/(2*pi) + 0.5) - maps phase to [-pi, pi]
2. **Phase unwrapping**: Iterative process starting from initial phase, adding princarg of consecutive differences
3. **Overlap-add synthesis**: Window length typically longer than hop size for smooth transitions
4. **Real-time vs offline**: Real-time MFPA uses simplified approach with latency tradeoff
5. **Sub-harmonics for rough/growl**: Added in frequency domain at fractional multiples of F0
