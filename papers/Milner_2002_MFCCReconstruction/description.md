This paper presents a method to reconstruct intelligible speech from MFCC feature vectors using the source-filter model, enabling dual-use vectors for both speech recognition and voice communication in distributed systems. The key contribution is showing that vocal tract filter coefficients can be derived from MFCCs by inverting to a smoothed magnitude spectrum and applying the Wiener-Khintchine theorem to obtain autocorrelation coefficients for LPC analysis. While not directly applicable to synthesis-from-phonemes, the work reinforces fundamental source-filter concepts and demonstrates that even heavily compressed spectral representations retain sufficient vocal tract information for intelligible speech.
