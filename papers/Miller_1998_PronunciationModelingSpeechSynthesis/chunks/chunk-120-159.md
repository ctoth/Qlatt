# Pages 120-159 Notes

## Chapters/Sections Covered
- Section 4.2: Experimental procedure (pp. 106-109)
- Section 4.2.1: Experiment on [schwa]/[barred-i] (pp. 111-115)
- Section 4.2.2: Experiment on [u]/[barred-u] (pp. 116-122)
- Section 4.2.3: Experiment on /a/ and /open-o/ (pp. 122-129)
- Section 4.2.4: Experiment on /o/ and /i/ (pp. 130-134)
- Section 4.3: Conclusions from acoustic analyses of allophony (pp. 135-138)
- **Chapter 5: Methods for learning segmental postlexical variation** (pp. 139+)
- Section 5.1: Creation of postlexical training materials (pp. 139+)
- Section 5.1.1: Alignment of lexical and postlexical phones (pp. 140-145)

## Key Findings

### Allophonic Distinction Experiments
- F2 (front-back) is more robust than F1 (high-low) for distinguishing schwa allophones [schwa] and [barred-i]
- Neural network with allophonic labels preserves vowel distinctions better than collapsed (single phonemic label) condition
- For [u]/[barred-u] experiment: /u/ fronting observed in Chicago dialect speaker (male, participating in sound change)
- Two norms exist for /u/: one back, one front - varies by word class (**iw** vs **uw**)
- Collapsing labels increases Euclidean distance from original speech, indicating degraded acoustic fidelity

### /a/ and /open-o/ Distribution Patterns
- Environments are somewhat skewed but not in perfect complementary distribution
- /open-o/ more common before voiceless fricatives and nasals
- /a/ more common before stops /p/, /b/, /t/, /d/
- Preceding /l/, /ng/, /g/: /open-o/ is much more common than /a/
- Preceding /n/, /k/, /b/: /a/ is much more common than /open-o/
- This environmental skewing explains why collapsed neural network could still distinguish them

### /o/ and /i/ Control Experiment
- These are truly contrastive phonemes with overlapping distributions and no complementary distribution
- Collapsing /i/ to /o/ causes "chaos" - random mixing, statistical significance still exists but two distinct acoustic clusters no longer map to original phoneme labels
- Demonstrates that when phonemes have truly overlapping distributions, collapsed condition fails catastrophically

### Main Conclusion on Allophony
- Allophone distinctions [u]/[barred-u], [schwa]/[barred-i], and /a//open-o/ can be predicted from context alone
- Explicit allophonic labels improve acoustic fidelity but may not be strictly necessary for preserving distinctions
- Duration and other non-spectral factors may help neural network distinguish allophones
- Vowel space dispersion may be important for intelligibility (Bradlow et al. 1996)

### Weak Vowel Merger
- Wells (1982, pp. 167-168) discusses pairs like *Lennon/Lenin* and the "Weak Vowel Merger"
- General American occupies intermediate position between merging schwa allophones and treating them as distinct
- Marginal distinctions exist between [u]/[barred-u] and [schwa]/[barred-i] for some speakers

### Word Class Effects on /u/ Fronting
- **iw** word class: reflexes of French *u* or Middle English diphthongs (*few*, *dew*)
- **uw** word class: words like *boot*, *do*
- Fronted /u/ correlates with **iw** word class membership
- Phonemic distinctiveness of **iw** was lost due to conditioning /j/ glide after apicals

## Equations Found

### Equation 4-1: Rotation of axes
$$\tan 2\theta = \frac{\text{covariance}(F1, F2)}{\text{variance}(F1) - \text{variance}(F2)}$$
- Used for drawing ellipses around vowel distributions
- Ellipse center = mean F1 and F2
- Major/minor axes = 2 standard deviations along F1 or F2

### Equation 4-2: Euclidean distance
$$d = \left(\sum_j |u_j - x_j|^2\right)^{1/2}$$
- Where *u* and *x* are vectors with *j* elements
- Used to measure distance between original speech and synthesized conditions

## Parameters/Rules Found

| Rule/Parameter | Description | Value/Pattern | Page |
|----------------|-------------|---------------|------|
| K-S significance threshold | Threshold for rejecting null hypothesis | p < 0.05 | 109 |
| ESPS formant settings | Window duration | 0.1 seconds | 108 |
| ESPS formant settings | Frame step | 0.005 seconds | 108 |
| Testing subset size | Harvard sentences for allophone testing | 97 out of 470 | 106 |
| Testing subset proportion | Proportion of data withheld from training | ~20% | 106 |
| Neural network epochs | Training duration for allophone experiments | 35 epochs | 111 |
| Dynamic programming costs | Substitution cost when symbols identical | 0 | 144 |
| Dynamic programming costs | Standard substitution cost (different symbols) | Non-zero (application specific) | 144 |

## Algorithms/Procedures

### Allophone Distinction Test Procedure
1. Train acoustic neural network on labeled speech corpus
2. Test on held-out subset (20% of data)
3. Compare three conditions:
   - Original: actual recorded speech
   - Normal: neural network with separate allophonic labels
   - Collapsed: neural network with single phonemic label for both allophones
4. Use two-dimensional Kolmogorov-Smirnov test on F1/F2 values
5. Use t-tests on individual formants (F1, F2) separately
6. Calculate Euclidean distances between conditions and original
7. Draw ellipses on F1/F2 plots (center = mean, axes = 2 SD)

### Dynamic Programming Alignment (Section 5.1.1)
1. Given: lexical pronunciation string and postlexical pronunciation string
2. Goal: align each lexical phone with its corresponding postlexical phone
3. Operations: insertion, deletion, substitution (each has cost)
4. Find least costly transformation path
5. Insert placeholders where deletion has occurred (e.g., /d/ -> null)
6. Use phonetic feature-based costs: similar sounds have lower substitution cost

### Pseudophone Collapsing Strategy
1. Identify phone pairs that differ only in subphonemic features
2. Collapse stop closure + release into single "pseudophone"
3. This avoids alignment problems where postlexical form has more segments than lexical form
4. Adapted from Sejnowski and Rosenberg (1987)

## Figures of Interest

- **Fig 4-1 (page 114):** Formant distribution of [schwa] and [barred-i] in original speech - shows overlapping but distinct clusters with [barred-i] fronter and higher
- **Fig 4-2 (page 115):** Same vowels in normal neural network - more overlap than original but still distinct
- **Fig 4-3 (page 116):** Same vowels in collapsed neural network - still shows two clumps despite single label
- **Fig 4-1 (page 120):** [u] and [barred-u] in original speech - completely non-overlapping but contiguous
- **Fig 4-2 (page 121):** [u] and [barred-u] in normal neural network - slight overlap now
- **Fig 4-3 (page 122):** [u] and [barred-u] in collapsed neural network - [barred-u] cloud almost wholly within [u] cloud
- **Fig 4-1 (page 125):** /a/ and /open-o/ in original speech - /open-o/ higher and backer with some overlap
- **Fig 4-4 (page 129):** Bar chart of phones following /a/ and /open-o/ - shows environmental distribution patterns
- **Fig 4-1 (page 131):** /o/ and /i/ in original speech - completely separate regions of vowel space
- **Fig 4-3 (page 134):** /o/ and /i/ in collapsed neural network - catastrophic mixing, two clouds but random assignment of labels

## Tables of Interest

- **Table 4-1 (page 107):** Allophone quantities in testing subset - shows [barred-i]=123, [schwa]=84, [u]=11, [barred-u]=26, etc.
- **Table 4-1 (page 112):** Hypothesis tests for [schwa]/[barred-i] - shows K-S and t-test p-values for each condition
- **Table 4-2 (page 113):** Euclidean distances for [schwa]/[barred-i] - normal condition closer to original than collapsed
- **Table 4-1 (page 118):** Hypothesis tests for [u]/[barred-u] - F2 significant in all conditions
- **Table 4-2 (page 119):** Euclidean distances for [u]/[barred-u] - only F2 of [u] more distant in collapsed
- **Table 4-1 (page 123):** Hypothesis tests for /a/ and /open-o/ - collapsed condition still significant for K-S and F2
- **Table 4-2 (page 124):** Euclidean distances for /a/ and /open-o/ - collapsed more distant from original
- **Table 4-1 (page 132):** Hypothesis tests for /o/ and /i/ - collapsed still significant but barely
- **Table 4-2 (page 132):** Euclidean distances for /o/ and /i/ - collapsed massively more distant (4703 vs 1510 for F2 of /i/)
- **Table 4-1 (page 138):** Inter-transcriber reliability at two locations - UCLA 77.5%/80.1%, OGI 55%/67% (with/without diacritics)
- **Table 5-1 (page 140):** Unaligned lexical and postlexical phones for "friendly"
- **Table 5-2 (page 141):** Aligned lexical and postlexical phones - shows placeholder insertion for deleted /d/
- **Table 5-3 (page 144):** Sequence comparison of "industry" and "interest" orthographies
- **Table 5-4 (page 144):** Operations required to transform "industry" to "interest"
- **Table 5-5 (page 145):** Unaligned lexical and postlexical phones for "top" without pseudophones

## Quotes Worth Preserving

> "Perhaps the most interesting outcome of the acoustic investigations of allophony described here is that the allophone distributions in F1/F2 space remained distinct for [u]/[barred-u], [schwa]/[barred-i] and /a/ / /open-o/ despite the removal of the individual allophone labels and features in the collapsed condition. This indicates that the allophony in those cases is predictable from context alone." (p. 135)

> "Label inventory seems to influence agreement more than knowledge of the language, because although transcribers were familiar with Spanish and English, they agreed more often in Spanish, with its smaller label inventory." - Lander et al. (1995, 169) (p. 138)

> "In the domain of aligning phonetic transcriptions, this would mean that perceptually small differences, such as [schwa] and [barred-i], would be considered just as erroneous as large differences such as [b] and [k]." (p. 144)

> "To avoid this complexity, some researchers have chosen to simplify this problem and impose a one-to-one mapping between orthography and phonetics (Sejnowski and Rosenberg 1987, Laporte 1997), resulting in a potential loss of explanatory value of their proposals." (p. 142)

## Implementation Notes

### For TTS Allophone Generation
- Do NOT necessarily need separate allophonic labels in training data
- Neural networks can learn allophonic variation from context alone (for complementarily distributed allophones)
- However, explicit allophonic labels improve acoustic fidelity
- Consider using broad-phonetic labeling (Barry and Fourcin level) rather than detailed allophonic transcription
- Diacritics for nasalization, aspiration hurt inter-transcriber reliability

### For Lexical-Postlexical Alignment
- Use dynamic programming (Kruskal 1983) for alignment
- Feature-based substitution costs work better than binary (match/no-match)
- Perceptually similar phones should have lower substitution cost
- Handle deletions by inserting placeholders in postlexical form
- Collapse stop closure + release into pseudophones to avoid alignment artifacts
- One-to-one alignment between lexical and postlexical phones is less problematic than orthography-to-phoneme alignment

### TIMIT Symbol Mappings
- [schwa] = 'ax'
- [barred-i] = 'ix'
- [u] = 'uw'
- [barred-u] = 'ux'
- /a/ = 'aa'
- /open-o/ = 'ao'
- /i/ = 'iy'
- /o/ = 'ow'

### Phonetic Environment Effects on /a/-/open-o/ Choice
- Before voiceless fricatives (/s/, /f/, /theta/): prefer /open-o/
- Before nasals: prefer /open-o/
- Before stops (/p/, /b/, /t/, /d/): prefer /a/
- Before /l/, /ng/, /g/: strongly prefer /open-o/
- Before /n/, /k/, /b/: strongly prefer /a/
- Before /m/: neutral

## Cross-References

### Papers Referenced
- Labov (1991, 1994) - Vowel fronting, phoneme class distinctions, near-mergers
- Labov, Yaeger and Steiner (1972) - Bimodal /u/ distributions
- Bradlow et al. (1996) - Vowel space dispersion and intelligibility
- Wells (1982) - Weak Vowel Merger, accents of English
- Kenyon and Knott (1953) - [u]/[barred-u] distinction in *brewed/brood*, *lute/loot*
- Giegerich (1992) - Phonemic status of schwa
- Thomas (1958) - Short *o* pronunciation in American English
- Bronstein (1960) - /a/ vs /open-o/ before velars and nasals
- Press et al. (1992) - Two-dimensional Kolmogorov-Smirnov test
- Zue and Laferriere (1979) - Gradient acoustic properties of flapping
- Pierrehumbert and Frisch (1997) - Acoustic correlates of glottalization
- Fulop and Keating (1996) - Inter-transcriber reliability on Switchboard
- Lander et al. (1995) - CSLU transcription reliability study
- Kiparsky (1985) - Structure preservation
- Kruskal (1983) - Dynamic programming for sequence alignment
- Sejnowski and Rosenberg (1987) - NETtalk, one-to-one letter-phoneme mapping
- Dedina and Nusbaum (1991) - Parsing spellings into consonant/vowel groups
- Covington (1996) - Consonant/vowel alignment for cognates
- Knight and Graehl (1997) - EM algorithm for alignment
- Van Coile (1991) - HMM for alignment
- Lucas and Damper (1992) - Neural network for alignment
- Luk and Damper (1991, 1992, 1993) - Image processing and DTW for alignment
- Lawrence and Kaye (1986) - Table-based alignment approach
- Gildea and Jurafsky (1996) - Feature-based alignment costs
- Riley and Ljolje (1996) - Feature-based alignment
- Nerbonne and Heeringa (1997) - Feature-based alignment for dialectology
- Guy (1980, 1991) - t,d deletion in sociolinguistics
- Reynolds (1994) - t,d deletion
- Randolph (1989) - t,d deletion in speech technology
- Browman and Goldstein (1990) - Gestural remnants of deletion
