# Abstract

## Original Text (Verbatim)

There are many scenarios in both speech synthesis and coding in which adjacent time-frames of speech are spectrally discontinuous. This paper addresses the topic of improving concatenative speech synthesis with a limited database by proposing methods to smooth, adjust, or interpolate the spectral transitions between speech segments. The objective is to produce natural-sounding speech via segment concatenation when formants and other spectral features do not align properly. We consider several methods for adjusting the spectra at the boundaries between waveform segments. Techniques examined include optimal coupling, waveform interpolation (WI), linear predictive parameter interpolation, and psychoacoustic closure. Several of these algorithms have been previously developed for either coding or synthesis, while others are enhanced. We also consider the connection between speech science and articulation in determining the type of smoothing appropriate for given phoneme–phoneme transitions. Moreover, this work incorporates the use of a recently-proposed auditory-neural based distance measure (ANBM), which employs a computational model of the auditory system to assess perceived spectral discontinuities. We demonstrate how actual ANBM scores can be used to help determine the need for smoothing. In addition, formal evaluation of four smoothing methods, using the ANBM and extensive listener tests, reveals that smoothing can distinctly improve the quality of speech but when applied inappropriately can also degrade the quality. It is shown that after proper spectral smoothing, or spectral interpolation, the final synthesized speech sounds more natural and has a more continuous spectral structure.

---

## Our Interpretation

This paper compares four spectral smoothing algorithms for improving concatenative speech synthesis when segment boundaries have spectral discontinuities. The key contribution is demonstrating that no single algorithm works best for all phoneme transitions—optimal coupling, waveform interpolation, LP techniques, and closure (psychoacoustic continuity effect) each have strengths and weaknesses depending on context. The authors propose using an auditory-based distance measure (ANBM) to automatically determine when smoothing is needed and which algorithm to apply, since indiscriminate smoothing can degrade synthesis quality.
