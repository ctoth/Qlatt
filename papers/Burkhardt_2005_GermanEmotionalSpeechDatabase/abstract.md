# Abstract

## Original Text (Verbatim)

The article describes a database of emotional speech. Ten actors (5 female and 5 male) simulated the emotions, producing 10 German utterances (5 short and 5 longer sentences) which could be used in everyday communication and are interpretable in all applied emotions.

The recordings were taken in an anechoic chamber with high-quality recording equipment. In addition to the sound electro-glottograms were recorded. The speech material comprises about 800 sentences (seven emotions * ten actors * ten sentences + some second versions).

The complete database was evaluated in a perception test regarding the recognisability of emotions and their naturalness. Utterances recognised better than 80% and judged as natural by more than 60% of the listeners were phonetically labelled in a narrow transcription with special markers for voice-quality, phonatory and articulatory settings and articulatory features.

The database can be accessed by the public via the internet (http://www.expressive-speech.net/emodb/).

---

## Our Interpretation

This paper documents the creation of the Berlin Database of Emotional Speech (EmoDB), a publicly available corpus of acted emotional speech in German covering seven emotions (neutral, anger, fear, joy, sadness, disgust, boredom) with rigorous perceptual validation. The key contribution is a well-controlled, high-quality emotional speech dataset with electro-glottograms and detailed phonetic annotations that has become a standard benchmark for emotion recognition research. For speech synthesis, this database provides ground truth examples of how acoustic parameters vary across emotions, useful for implementing expressive TTS with emotion-specific prosody and voice quality modifications.
